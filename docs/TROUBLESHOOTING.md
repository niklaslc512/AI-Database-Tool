# æ•…éšœæ’é™¤æŒ‡å—

## ğŸ” é—®é¢˜è¯Šæ–­æµç¨‹

é‡åˆ°é—®é¢˜æ—¶ï¼Œè¯·æŒ‰ä»¥ä¸‹é¡ºåºè¿›è¡Œæ’æŸ¥ï¼š

1. **æ£€æŸ¥æœåŠ¡çŠ¶æ€** - ç¡®è®¤æ‰€æœ‰æœåŠ¡æ­£å¸¸è¿è¡Œ
2. **æŸ¥çœ‹æ—¥å¿—** - åˆ†æé”™è¯¯æ—¥å¿—æ‰¾å‡ºæ ¹æœ¬åŸå› 
3. **éªŒè¯é…ç½®** - æ£€æŸ¥ç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶
4. **æµ‹è¯•è¿æ¥** - éªŒè¯ç½‘ç»œå’Œæ•°æ®åº“è¿æ¥
5. **èµ„æºæ£€æŸ¥** - ç¡®è®¤ç³»ç»Ÿèµ„æºå……è¶³

## ğŸš€ å¯åŠ¨é—®é¢˜

### æœåŠ¡æ— æ³•å¯åŠ¨

**ç—‡çŠ¶**: Dockerå®¹å™¨æˆ–æœåŠ¡å¯åŠ¨å¤±è´¥

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥DockeræœåŠ¡çŠ¶æ€
sudo systemctl status docker

# 2. æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker-compose logs backend
docker-compose logs frontend
docker-compose logs postgres

# 3. æ£€æŸ¥ç«¯å£å ç”¨
sudo netstat -tlnp | grep :3000
sudo netstat -tlnp | grep :5432

# 4. éªŒè¯ç¯å¢ƒå˜é‡
docker-compose config
```

**å¸¸è§è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥ `.env` æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”é…ç½®æ­£ç¡®
- ç¡®è®¤ç«¯å£æœªè¢«å…¶ä»–æœåŠ¡å ç”¨
- éªŒè¯Dockeræœ‰è¶³å¤Ÿæƒé™è®¿é—®æ–‡ä»¶
- æ£€æŸ¥é˜²ç«å¢™è®¾ç½®

### æ•°æ®åº“è¿æ¥å¤±è´¥

**ç—‡çŠ¶**: åç«¯æœåŠ¡æ— æ³•è¿æ¥åˆ°PostgreSQL

**é”™è¯¯ä¿¡æ¯**:
```
Error: connect ECONNREFUSED 127.0.0.1:5432
Error: password authentication failed for user "postgres"
```

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥PostgreSQLå®¹å™¨çŠ¶æ€
docker ps | grep postgres
docker logs ai-database-postgres

# 2. æµ‹è¯•æ•°æ®åº“è¿æ¥
docker exec -it ai-database-postgres psql -U postgres -d ai_database

# 3. éªŒè¯è¿æ¥å­—ç¬¦ä¸²
echo $DATABASE_URL

# 4. æ£€æŸ¥ç½‘ç»œè¿æ¥
docker network ls
docker network inspect ai-database_default
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# é‡ç½®æ•°æ®åº“å¯†ç 
docker-compose down
docker volume rm ai-database_postgres_data
docker-compose up -d postgres

# æ‰‹åŠ¨åˆ›å»ºæ•°æ®åº“
docker exec -it ai-database-postgres createdb -U postgres ai_database

# è¿è¡Œæ•°æ®åº“è¿ç§»
docker exec -it ai-database-backend npm run db:migrate
```

### å‰ç«¯æ— æ³•è®¿é—®

**ç—‡çŠ¶**: æµè§ˆå™¨æ— æ³•æ‰“å¼€å‰ç«¯é¡µé¢

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥å‰ç«¯å®¹å™¨çŠ¶æ€
docker ps | grep frontend
docker logs ai-database-frontend

# 2. æµ‹è¯•ç«¯å£è®¿é—®
curl -I http://localhost:80
curl -I http://localhost:3000/health

# 3. æ£€æŸ¥Nginxé…ç½®
docker exec -it ai-database-frontend nginx -t
```

**è§£å†³æ–¹æ¡ˆ**:
- ç¡®è®¤å‰ç«¯æ„å»ºæˆåŠŸ
- æ£€æŸ¥Nginxé…ç½®æ–‡ä»¶è¯­æ³•
- éªŒè¯APIä»£ç†é…ç½®æ­£ç¡®
- æ£€æŸ¥SSLè¯ä¹¦é…ç½®

## ğŸ”Œ è¿æ¥é—®é¢˜

### APIè¯·æ±‚å¤±è´¥

**ç—‡çŠ¶**: å‰ç«¯æ— æ³•è°ƒç”¨åç«¯API

**é”™è¯¯ä¿¡æ¯**:
```
CORS error: Access to fetch at 'http://localhost:3000/api/v1/users/me' 
from origin 'http://localhost:8080' has been blocked
```

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥CORSé…ç½®
curl -H "Origin: http://localhost:8080" \
     -H "Access-Control-Request-Method: GET" \
     -H "Access-Control-Request-Headers: X-Requested-With" \
     -X OPTIONS \
     http://localhost:3000/api/v1/users/me

# 2. éªŒè¯APIç«¯ç‚¹
curl -X GET http://localhost:3000/api/v1/health

# 3. æ£€æŸ¥ç½‘ç»œè¿æ¥
ping localhost
telnet localhost 3000
```

**è§£å†³æ–¹æ¡ˆ**:
```typescript
// backend/src/app.ts - æ›´æ–°CORSé…ç½®
app.use(cors({
  origin: [
    'http://localhost:8080',
    'http://localhost:3000',
    'https://your-domain.com'
  ],
  credentials: true
}));
```

### æ•°æ®åº“æŸ¥è¯¢è¶…æ—¶

**ç—‡çŠ¶**: SQLæŸ¥è¯¢æ‰§è¡Œæ—¶é—´è¿‡é•¿æˆ–è¶…æ—¶

**é”™è¯¯ä¿¡æ¯**:
```
Error: Query timeout after 30000ms
Error: Connection terminated unexpectedly
```

**æ’æŸ¥æ­¥éª¤**:
```sql
-- 1. æ£€æŸ¥æ´»è·ƒè¿æ¥
SELECT * FROM pg_stat_activity WHERE state = 'active';

-- 2. æŸ¥çœ‹æ…¢æŸ¥è¯¢
SELECT query, query_start, state, wait_event 
FROM pg_stat_activity 
WHERE query_start < NOW() - INTERVAL '1 minute';

-- 3. æ£€æŸ¥é”ç­‰å¾…
SELECT * FROM pg_locks WHERE NOT granted;

-- 4. åˆ†ææŸ¥è¯¢è®¡åˆ’
EXPLAIN ANALYZE SELECT * FROM your_table WHERE condition;
```

**è§£å†³æ–¹æ¡ˆ**:
```sql
-- ç»ˆæ­¢é•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢
SELECT pg_terminate_backend(pid) 
FROM pg_stat_activity 
WHERE query_start < NOW() - INTERVAL '5 minutes';

-- æ·»åŠ ç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢
CREATE INDEX CONCURRENTLY idx_table_column ON table_name(column_name);

-- è°ƒæ•´è¿æ¥æ± é…ç½®
-- backend/src/config/database.ts
const pool = new Pool({
  max: 20,
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 5000,
  query_timeout: 60000
});
```

## ğŸ¤– AIæœåŠ¡é—®é¢˜

### OpenAI APIè°ƒç”¨å¤±è´¥

**ç—‡çŠ¶**: AIæŸ¥è¯¢åŠŸèƒ½æ— æ³•æ­£å¸¸å·¥ä½œ

**é”™è¯¯ä¿¡æ¯**:
```
Error: Request failed with status code 401
Error: You exceeded your current quota
Error: Rate limit exceeded
```

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. éªŒè¯APIå¯†é’¥
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
     https://api.openai.com/v1/models

# 2. æ£€æŸ¥é…é¢ä½¿ç”¨æƒ…å†µ
# ç™»å½•OpenAIæ§åˆ¶å°æŸ¥çœ‹ä½¿ç”¨æƒ…å†µ

# 3. æµ‹è¯•APIè¿æ¥
node -e "console.log(process.env.OPENAI_API_KEY)"
```

**è§£å†³æ–¹æ¡ˆ**:
```typescript
// backend/src/services/OpenAIService.ts - æ·»åŠ é‡è¯•æœºåˆ¶
class OpenAIService {
  async generateSQL(query: string, retries = 3): Promise<any> {
    try {
      const response = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [/* ... */],
        timeout: 30000
      });
      return response;
    } catch (error) {
      if (retries > 0 && error.status === 429) {
        await new Promise(resolve => setTimeout(resolve, 1000));
        return this.generateSQL(query, retries - 1);
      }
      throw error;
    }
  }
}
```

### AIå“åº”è§£æé”™è¯¯

**ç—‡çŠ¶**: AIè¿”å›çš„SQLæ— æ³•æ­£ç¡®è§£æ

**é”™è¯¯ä¿¡æ¯**:
```
Error: Invalid JSON response from AI
Error: Generated SQL contains syntax errors
```

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥AIå“åº”æ—¥å¿—
docker logs ai-database-backend | grep "AI Response"

# 2. éªŒè¯æç¤ºè¯æ¨¡æ¿
cat backend/src/prompts/sql-generation.ts

# 3. æµ‹è¯•SQLè¯­æ³•
psql -U postgres -d ai_database -c "EXPLAIN SELECT 1;"
```

**è§£å†³æ–¹æ¡ˆ**:
```typescript
// æ”¹è¿›AIå“åº”éªŒè¯
class AISQLController {
  private validateSQL(sql: string): boolean {
    // åŸºæœ¬SQLè¯­æ³•æ£€æŸ¥
    const forbiddenKeywords = ['DROP', 'DELETE', 'TRUNCATE', 'ALTER'];
    const upperSQL = sql.toUpperCase();
    
    return !forbiddenKeywords.some(keyword => 
      upperSQL.includes(keyword)
    );
  }
  
  private async testSQL(sql: string, connectionId: string): Promise<boolean> {
    try {
      // ä½¿ç”¨EXPLAINæµ‹è¯•SQLè¯­æ³•
      await this.databaseService.executeQuery(
        connectionId, 
        `EXPLAIN ${sql}`
      );
      return true;
    } catch (error) {
      return false;
    }
  }
}
```

## ğŸ’¾ æ•°æ®é—®é¢˜

### æ•°æ®ä¸¢å¤±æˆ–æŸå

**ç—‡çŠ¶**: æ•°æ®åº“æ•°æ®å¼‚å¸¸æˆ–ä¸¢å¤±

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥æ•°æ®åº“å®Œæ•´æ€§
docker exec -it ai-database-postgres pg_dump -U postgres ai_database > backup.sql

# 2. éªŒè¯è¡¨ç»“æ„
psql -U postgres -d ai_database -c "\dt"
psql -U postgres -d ai_database -c "\d users"

# 3. æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
psql -U postgres -d ai_database -c "SELECT COUNT(*) FROM users;"
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ä»å¤‡ä»½æ¢å¤æ•°æ®
docker exec -i ai-database-postgres psql -U postgres ai_database < backup.sql

# é‡æ–°è¿è¡Œè¿ç§»
docker exec -it ai-database-backend npm run db:migrate:reset
docker exec -it ai-database-backend npm run db:seed
```

### è¿ç§»å¤±è´¥

**ç—‡çŠ¶**: æ•°æ®åº“è¿ç§»è„šæœ¬æ‰§è¡Œå¤±è´¥

**é”™è¯¯ä¿¡æ¯**:
```
Error: relation "users" already exists
Error: column "email" of relation "users" does not exist
```

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥è¿ç§»çŠ¶æ€
psql -U postgres -d ai_database -c "SELECT * FROM schema_migrations;"

# 2. æŸ¥çœ‹è¡¨ç»“æ„
psql -U postgres -d ai_database -c "\d+ users"

# 3. æ£€æŸ¥è¿ç§»æ–‡ä»¶
ls -la backend/migrations/
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ‰‹åŠ¨å›æ»šè¿ç§»
psql -U postgres -d ai_database -c "DELETE FROM schema_migrations WHERE version = '20250115120000';"

# é‡æ–°è¿è¡Œè¿ç§»
docker exec -it ai-database-backend npm run db:migrate

# å¦‚æœéœ€è¦å®Œå…¨é‡ç½®
docker-compose down
docker volume rm ai-database_postgres_data
docker-compose up -d
```

## ğŸ”§ æ€§èƒ½é—®é¢˜

### å“åº”é€Ÿåº¦æ…¢

**ç—‡çŠ¶**: APIå“åº”æ—¶é—´è¿‡é•¿

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥ç³»ç»Ÿèµ„æº
docker stats
top
df -h

# 2. åˆ†ææ…¢æŸ¥è¯¢
psql -U postgres -d ai_database -c "
SELECT query, mean_exec_time, calls 
FROM pg_stat_statements 
ORDER BY mean_exec_time DESC 
LIMIT 10;"

# 3. æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ
ping your-database-host
curl -w "@curl-format.txt" -o /dev/null -s http://localhost:3000/api/v1/health
```

**è§£å†³æ–¹æ¡ˆ**:
```sql
-- å¯ç”¨æŸ¥è¯¢ç»Ÿè®¡
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- æ·»åŠ ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_users_email ON users(email);
CREATE INDEX CONCURRENTLY idx_logs_created_at ON sql_execute_logs(created_at);

-- ä¼˜åŒ–æŸ¥è¯¢
ANALYZE users;
VACUUM ANALYZE sql_execute_logs;
```

```typescript
// æ·»åŠ ç¼“å­˜æœºåˆ¶
import Redis from 'ioredis';

class CacheService {
  private redis = new Redis(process.env.REDIS_URL);
  
  async get(key: string): Promise<any> {
    const cached = await this.redis.get(key);
    return cached ? JSON.parse(cached) : null;
  }
  
  async set(key: string, value: any, ttl = 3600): Promise<void> {
    await this.redis.setex(key, ttl, JSON.stringify(value));
  }
}
```

### å†…å­˜ä½¿ç”¨è¿‡é«˜

**ç—‡çŠ¶**: å®¹å™¨å†…å­˜ä½¿ç”¨ç‡æŒç»­ä¸Šå‡

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. ç›‘æ§å†…å­˜ä½¿ç”¨
docker stats --no-stream

# 2. æ£€æŸ¥Node.jså†…å­˜
docker exec -it ai-database-backend node -e "console.log(process.memoryUsage())"

# 3. åˆ†æå†…å­˜æ³„æ¼
# ä½¿ç”¨Node.jså†…å­˜åˆ†æå·¥å…·
npm install -g clinic
clinic doctor -- node dist/index.js
```

**è§£å†³æ–¹æ¡ˆ**:
```typescript
// ä¼˜åŒ–å†…å­˜ä½¿ç”¨
class DatabaseService {
  async executeQuery(sql: string) {
    const client = await this.pool.connect();
    try {
      // ä½¿ç”¨æµå¼æŸ¥è¯¢å¤„ç†å¤§ç»“æœé›†
      const query = new QueryStream(sql);
      const stream = client.query(query);
      
      const results = [];
      for await (const row of stream) {
        results.push(row);
        // é™åˆ¶ç»“æœé›†å¤§å°
        if (results.length > 10000) {
          break;
        }
      }
      
      return results;
    } finally {
      client.release();
    }
  }
}
```

```yaml
# docker-compose.yml - è®¾ç½®å†…å­˜é™åˆ¶
services:
  backend:
    mem_limit: 1g
    memswap_limit: 1g
  postgres:
    mem_limit: 2g
    memswap_limit: 2g
```

## ğŸ” å®‰å…¨é—®é¢˜

### è®¤è¯å¤±è´¥

**ç—‡çŠ¶**: ç”¨æˆ·æ— æ³•ç™»å½•æˆ–TokenéªŒè¯å¤±è´¥

**é”™è¯¯ä¿¡æ¯**:
```
Error: Invalid credentials
Error: Token has expired
Error: JsonWebTokenError: invalid signature
```

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. éªŒè¯JWTå¯†é’¥
echo $JWT_SECRET | wc -c  # åº”è¯¥è‡³å°‘32å­—ç¬¦

# 2. æ£€æŸ¥Tokenæ ¼å¼
node -e "console.log(require('jsonwebtoken').decode('your-token'))"

# 3. éªŒè¯ç”¨æˆ·å¯†ç 
psql -U postgres -d ai_database -c "SELECT id, username, password_hash FROM users WHERE username = 'admin';"
```

**è§£å†³æ–¹æ¡ˆ**:
```typescript
// é‡ç½®ç”¨æˆ·å¯†ç 
import bcrypt from 'bcrypt';

const newPassword = 'new-secure-password';
const saltRounds = 12;
const hashedPassword = await bcrypt.hash(newPassword, saltRounds);

// æ›´æ–°æ•°æ®åº“
psql -U postgres -d ai_database -c "
UPDATE users 
SET password_hash = '${hashedPassword}' 
WHERE username = 'admin';"
```

### SQLæ³¨å…¥é£é™©

**ç—‡çŠ¶**: å‘ç°æ½œåœ¨çš„SQLæ³¨å…¥æ¼æ´

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥æŸ¥è¯¢æ—¥å¿—
grep -i "drop\|delete\|update\|insert" /var/log/postgresql/postgresql.log

# 2. åˆ†æç”¨æˆ·è¾“å…¥
docker logs ai-database-backend | grep "User input:"

# 3. å®¡è®¡ä»£ç 
grep -r "query.*+" backend/src/
grep -r "\${.*}" backend/src/
```

**è§£å†³æ–¹æ¡ˆ**:
```typescript
// ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢
class DatabaseService {
  async executeQuery(sql: string, params: any[] = []) {
    // é”™è¯¯æ–¹å¼ - å®¹æ˜“SQLæ³¨å…¥
    // const query = `SELECT * FROM users WHERE id = ${userId}`;
    
    // æ­£ç¡®æ–¹å¼ - å‚æ•°åŒ–æŸ¥è¯¢
    const query = 'SELECT * FROM users WHERE id = $1';
    return await this.pool.query(query, [userId]);
  }
  
  // éªŒè¯å’Œæ¸…ç†ç”¨æˆ·è¾“å…¥
  private sanitizeInput(input: string): string {
    return input.replace(/[;'"\-\-]/g, '');
  }
}
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### æ—¥å¿—åˆ†æ

**æŸ¥çœ‹åº”ç”¨æ—¥å¿—**:
```bash
# å®æ—¶æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f backend
docker-compose logs -f frontend

# è¿‡æ»¤é”™è¯¯æ—¥å¿—
docker-compose logs backend | grep ERROR
docker-compose logs backend | grep -i "error\|exception\|failed"

# æŸ¥çœ‹ç‰¹å®šæ—¶é—´æ®µæ—¥å¿—
docker-compose logs --since="2025-01-15T10:00:00" backend
```

**æ—¥å¿—çº§åˆ«é…ç½®**:
```typescript
// backend/src/utils/logger.ts
import winston from 'winston';

const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.json()
  ),
  transports: [
    new winston.transports.Console(),
    new winston.transports.File({ 
      filename: 'logs/error.log', 
      level: 'error' 
    }),
    new winston.transports.File({ 
      filename: 'logs/combined.log' 
    })
  ]
});
```

### æ€§èƒ½ç›‘æ§

**ç³»ç»ŸæŒ‡æ ‡ç›‘æ§**:
```bash
# CPUå’Œå†…å­˜ä½¿ç”¨
watch -n 1 'docker stats --no-stream'

# ç£ç›˜ä½¿ç”¨
df -h
du -sh /var/lib/docker/volumes/

# ç½‘ç»œè¿æ¥
netstat -an | grep :3000
ss -tuln | grep :5432
```

**æ•°æ®åº“æ€§èƒ½ç›‘æ§**:
```sql
-- è¿æ¥æ•°ç›‘æ§
SELECT count(*) as connections, state 
FROM pg_stat_activity 
GROUP BY state;

-- æ…¢æŸ¥è¯¢ç›‘æ§
SELECT query, mean_exec_time, calls, total_exec_time
FROM pg_stat_statements 
WHERE mean_exec_time > 1000
ORDER BY mean_exec_time DESC;

-- é”ç­‰å¾…ç›‘æ§
SELECT blocked_locks.pid AS blocked_pid,
       blocked_activity.usename AS blocked_user,
       blocking_locks.pid AS blocking_pid,
       blocking_activity.usename AS blocking_user,
       blocked_activity.query AS blocked_statement
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity 
  ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks 
  ON blocking_locks.locktype = blocked_locks.locktype
JOIN pg_catalog.pg_stat_activity blocking_activity 
  ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted;
```

## ğŸ†˜ ç´§æ€¥æ¢å¤

### æœåŠ¡å¿«é€Ÿæ¢å¤

```bash
# 1. åœæ­¢æ‰€æœ‰æœåŠ¡
docker-compose down

# 2. æ¸…ç†å®¹å™¨å’Œç½‘ç»œ
docker system prune -f
docker network prune -f

# 3. é‡æ–°æ„å»ºå’Œå¯åŠ¨
docker-compose build --no-cache
docker-compose up -d

# 4. éªŒè¯æœåŠ¡çŠ¶æ€
docker-compose ps
curl http://localhost:3000/health
```

### æ•°æ®å¤‡ä»½å’Œæ¢å¤

```bash
# åˆ›å»ºæ•°æ®å¤‡ä»½
docker exec ai-database-postgres pg_dump -U postgres ai_database > backup_$(date +%Y%m%d_%H%M%S).sql

# æ¢å¤æ•°æ®
docker exec -i ai-database-postgres psql -U postgres ai_database < backup_20250115_120000.sql

# å¤‡ä»½Dockerå·
docker run --rm -v ai-database_postgres_data:/data -v $(pwd):/backup alpine tar czf /backup/postgres_backup.tar.gz -C /data .

# æ¢å¤Dockerå·
docker run --rm -v ai-database_postgres_data:/data -v $(pwd):/backup alpine tar xzf /backup/postgres_backup.tar.gz -C /data
```

## ğŸ“ è·å–å¸®åŠ©

### æ”¶é›†è¯Šæ–­ä¿¡æ¯

è¿è¡Œä»¥ä¸‹è„šæœ¬æ”¶é›†ç³»ç»Ÿä¿¡æ¯ï¼š

```bash
#!/bin/bash
# collect-diagnostics.sh

echo "=== System Information ==="
uname -a
docker --version
docker-compose --version

echo "\n=== Container Status ==="
docker-compose ps

echo "\n=== Resource Usage ==="
docker stats --no-stream

echo "\n=== Recent Logs ==="
docker-compose logs --tail=50 backend
docker-compose logs --tail=50 postgres

echo "\n=== Network Configuration ==="
docker network ls
netstat -tlnp | grep -E ':(3000|5432|80|443)'

echo "\n=== Disk Usage ==="
df -h
docker system df
```

### è”ç³»æ”¯æŒ

åœ¨å¯»æ±‚å¸®åŠ©æ—¶ï¼Œè¯·æä¾›ï¼š

1. **é”™è¯¯æè¿°** - è¯¦ç»†æè¿°é—®é¢˜ç°è±¡
2. **é”™è¯¯æ—¥å¿—** - ç›¸å…³çš„é”™è¯¯æ—¥å¿—ä¿¡æ¯
3. **ç¯å¢ƒä¿¡æ¯** - æ“ä½œç³»ç»Ÿã€Dockerç‰ˆæœ¬ç­‰
4. **é…ç½®æ–‡ä»¶** - ç›¸å…³é…ç½®æ–‡ä»¶ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰
5. **é‡ç°æ­¥éª¤** - é—®é¢˜é‡ç°çš„å…·ä½“æ­¥éª¤

**æ”¯æŒæ¸ é“**:
- ğŸ“§ **é‚®ä»¶**: support@your-domain.com
- ğŸ› **GitHub Issues**: [é¡¹ç›®Issuesé¡µé¢](https://github.com/your-repo/issues)
- ğŸ’¬ **è®¨è®ºåŒº**: [GitHub Discussions](https://github.com/your-repo/discussions)
- ğŸ“– **æ–‡æ¡£**: [åœ¨çº¿æ–‡æ¡£](https://docs.your-domain.com)

---

> ğŸ’¡ **æç¤º**: å¤§å¤šæ•°é—®é¢˜éƒ½å¯ä»¥é€šè¿‡é‡å¯æœåŠ¡ã€æ£€æŸ¥é…ç½®å’ŒæŸ¥çœ‹æ—¥å¿—æ¥è§£å†³ã€‚é‡åˆ°é—®é¢˜æ—¶ä¿æŒå†·é™ï¼ŒæŒ‰æ­¥éª¤æ’æŸ¥ï¼